---
title: "Predictors of Hit-and-Run in Car Accidents"
author: "Nicole Deng, Kevin Pang, Christina Xu"
date: "`r Sys.Date()`"
output: 
  html_document:
    toc: true
    highlight: kate
    theme: readable
---

# Problem Statement

# Data Description
```{r}
library(qacBase)
ped <- read.csv("ped_crashes.csv")
contents(ped)
df_plot(ped)
histograms(ped)
barcharts(ped)
```

# Data Preprocessing
```{r}
library(dplyr)
ped <- ped %>% 
  select(-c("Crash.Day","City.or.Township","Party.Type")) %>% #party type only one value
  rename(year = Crash.Year,
         month = Crash.Month,
         time = Time.of.Day,
         weekday = Day.of.Week,
         intersection = Crash..Intersection,
         hit_run = Crash..Hit.and.Run,
         light = Lighting.Conditions,
         weather = Weather.Conditions..2016..,
         speedLimit = Speed.Limit.at.Crash.Site,
         worstInjury = Worst.Injury.in.Crash,
         age = Person.Age,
         gender = Person.Gender) %>% 
  filter(weather != "Uncoded & errors",
         gender != "Uncoded & errors",
         age != "DOB invalid",
         age != "Less than 1 year old",
         light != "Unknown",
         weather != "Unknown",
         speedLimit != "Uncoded & errors") %>% 
  mutate(speedLimit = as.numeric(speedLimit),
         age = as.numeric(age))

str(ped)
```

Before anything else was changed, variables were first evaluated for their statistical meaning and value ranges to determine whether they should be included or eliminated. Expressly, crash day, city or township, and party type are excluded due to their uselessness. The issue with crash day and city or township is that they both have too many categories—more than 30, far exceeding the maximum number that should be utilized for a categorical variable. On the other hand, party type only has a single value without any variability, making it useless in predicting the outcome variable. After excluding these variables, all remaining variables were renamed for convenience. 

According to the result of checking contents of this dataset, several categorical variables have coded missing values as "unknown" or "uncoded." Observations with missing values are excluded, and one observation has the value "less than one year old" for age, which was later proved insignificant and thus excluded as an outlier. After excluding all the missing values, we have 1332 observations, which is still a decent sample to apply our models.

Eventually, age and speed limit types were recoded as numeric variables instead of their original character type.

```{r}
# recode time as categorical variable
morning <- c("6:00 AM - 7:00 AM" ,"7:00 AM - 8:00 AM","8:00 AM - 9:00 AM",
             "9:00 AM - 10:00 AM","10:00 AM - 11:00 AM","11:00 AM - 12:00 noon")
afternoon <- c("12:00 noon - 1:00 PM","1:00 PM - 2:00 PM","2:00 PM - 3:00 PM",
               "3:00 PM - 4:00 PM","4:00 PM - 5:00 PM","5:00 PM - 6:00 PM")
night <- c("6:00 PM - 7:00 PM","7:00 PM - 8:00 PM","8:00 PM - 9:00 PM",
           "9:00 PM - 10:00 PM","10:00 PM - 11:00 PM","11:00 PM - 12:00 midnight")
lateNight <- c("12:00 midnight - 1:00 AM","1:00 AM - 2:00 AM","2:00 AM - 3:00 AM",
               "3:00 AM - 4:00 AM","4:00 AM - 5:00 AM","5:00 AM - 6:00 AM")

ped$time <- ifelse(ped$time %in% morning, "morning",
                   ifelse(ped$time %in% afternoon, "afternoon",
                          ifelse(ped$time %in% night, "night", "midnight")))

# recode worst injury
ped$worstInjury <- recode(ped$worstInjury, 
                          "Suspected serious injury (A)" = "4", 
                          "Suspected minor injury (B)" = "3",
                          "Possible injury (C)" = "2",
                          "No injury (O)"  = "1", 
                          "Fatal injury (K)" = "5")

#recode intersection
ped$intersection <- recode(ped$intersection, 
                           "Not intersection crash" = "0", 
                           "Intersection crash" = "1")

#recode hit_run
ped$hit_run <- factor(ifelse(ped$hit_run == "Hit-and-run","yes","no"))
```

After using tidyverse to clean the data, we divided the four categories of time values—which record the precise hour in a day—into the morning, afternoon, midnight, and late at night. 24 hours of a day are divided into four groups:

  + Morning: 6 am to 12 pm
  + Afternoon: 12 pm to 6 pm
  + Midnight: 6 pm to 12 am
  + Late night: 12 am to 6am

Even if the precise time of day may be helpful, compressed categories may illustrate the influence more clearly.

Since an implied order of injury level existed, levels of the worst injury were also recoded. The severity of the injury was represented by numerical levels, from the least severe to the most severe. 

For ease, the two levels of the variable intersection were recoded. 

Our outcome variable, hit run, was ultimately recoded as a factor with two levels, "yes" and "no."

# Machine Learning Approaches

## set up train control method
```{r}
library(caret)
set.seed(1234)

index <- createDataPartition(ped$hit_run, p=.8, list = FALSE)
train <- ped[index,]
test <- ped[-index,]

train.control <- trainControl(method = "cv",
                              number = 10,
                              summaryFunction = twoClassSummary,
                              classProbs = TRUE,
                              sampling = "smote")
```

The initial dataset was divided into two sets: a training set and a testing set. The two-level outcome variable hit_run was classified using 10-fold cross-validation and a two-class summary function. It is expected that the sampling approach adopted, smote, will lessen the adverse effects of the imbalanced hit_run value distribution on model training and prediction. All of our subsequent models in this section were subjected to the same training control to compare the performance of various models.

## Basic Logistic Regression

Fit the model:
```{r, warning=FALSE}
set.seed(1234)
model.lr <- train(hit_run ~ ., 
                  data = train,
                  trControl = train.control,
                  method = "glm",
                  family = "binomial",
                  metric = "ROC")

summary(model.lr)
formatC(exp(coef(model.lr$finalModel)), format = "g",digits = 3)

varImp(model.lr)
plot(varImp(model.lr))

```

Test model performance:
```{r}
pred <- as.factor(predict(model.lr, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```
## Logistic Regression with Lasso
```{r, warning=FALSE}
lambda <- 10^seq(-3, 3, length=100)

set.seed(1234)
model.lasso <- train(
  hit_run ~., 
  data = train, 
  method = "glmnet",
  metric = "ROC", 
  family = "binomial",
  trControl = train.control,
  tuneGrid = data.frame(alpha = 1, lambda = lambda)
)

model.lasso
coef(model.lasso$finalModel, as.numeric(formatC(model.lasso$bestTune$lambda,format = "f")))

varImp(model.lasso)
plot(varImp(model.lasso))
```

Test model performance:
```{r}
pred <- as.factor(predict(model.lasso, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```

## Backward Selection with AIC
```{r, warning = FALSE}
set.seed(1234)
model.stepAIC <- train(hit_run ~ ., data=train,
                       method="glmStepAIC",
                       trControl = train.control,
                       metric="ROC",
                       trace = FALSE)

model.stepAIC
summary(model.stepAIC$finalModel)
```

Test model performance:
```{r}
pred <- as.factor(predict(model.stepAIC, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```

## Stochastic Gradient Boost
```{r, warning=FALSE}
set.seed(1234)
model.gbm <- train(hit_run ~.,
                   data = train,
                   method = "gbm",
                   tuneLength = 10,
                   trControl = train.control,
                   metric = "ROC",
                   verbose = FALSE)

model.gbm
model.gbm$finalModel

# check variable importance
library(gbm)
varImportance <- summary(model.gbm)
rownames(varImportance) <- NULL
varImportance$rel.inf <- round(varImportance$rel.inf, 3)
colnames(varImportance) <- c("variable","rel.inf")
varImportance
```


Test model performance:
```{r}
pred <- as.factor(predict(model.gbm, test))
confusionMatrix(pred, test$hit_run, positive = "yes")
```

## Extreme Gradient Boost
```{r, warning=FALSE}
set.seed(1234)
model.xgb <- train(hit_run~.,
                   data = train,
                   method = "xgbTree",
                   metric = "ROC",
                   tuneLength = 5,
                   verbose = FALSE,
                   verbosity = 0,
                   trControl = train.control)

model.xgb
model.xgb$bestTune

varImp(model.xgb)
plot(varImp(model.xgb))

```

Test model performance:
```{r}
pred <- as.factor(predict(model.xgb, test))
confusionMatrix(pred, test$hit_run, positive = "yes")
```


## Random Forest

Fit the model:
```{r, warning=FALSE}
library(randomForest)
set.seed(1234)
model.rf<-train(hit_run~., 
                data=train,
                method='rf',
                metric='ROC',
                tuneLength=8,
                ntree=100,
                trControl=train.control,
                importance=TRUE)
model.rf
model.rf$finalModel

varImp(model.rf)
plot(varImp(model.rf)) 
```

Test model performance:
```{r}
pred <- as.factor(predict(model.rf,test))
confusionMatrix(pred, test$hit_run, positive="yes")
```

## ANN
```{r, warning=FALSE}
library(neuralnet)
set.seed(1234)
model.ann <- train(hit_run ~ ., 
                   data=train,
                   method="nnet",
                   tuneLength=10,  
                   metric="ROC",
                   trControl=train.control,
                   preProcess=c("range"),
                   trace=FALSE)

model.ann
model.ann$finalModel

varImp(model.ann)
plot(varImp(model.ann))
```

Test model performance:
```{r}
pred <- as.factor(predict(model.ann, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```


# Results

## Model Comparison
```{r}
results <- resamples(list(gbm = model.gbm,
                     ann = model.ann,
                     rf = model.rf,
                     lasso = model.lasso,
                     logistic = model.lr,
                     stepAIC = model.stepAIC
                     ))
summary(results)
bwplot(results)
```

## try different sampling method

Under sampling:
```{r}
train.control <- trainControl(method = "cv",
                              number = 10,
                              summaryFunction = twoClassSummary,
                              classProbs = TRUE,
                              sampling = "down")

lambda <- 10^seq(-3, 3, length=100)

set.seed(1234)
model.lasso.down <- train(
  hit_run ~., 
  data = train, 
  method = "glmnet",
  metric = "ROC", 
  family = "binomial",
  trControl = train.control,
  tuneGrid = data.frame(alpha = 1, lambda = lambda)
)

pred <- as.factor(predict(model.lasso.down, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```

Over sampling:
```{r}
train.control <- trainControl(method = "cv",
                              number = 10,
                              summaryFunction = twoClassSummary,
                              classProbs = TRUE,
                              sampling = "up")

set.seed(1234)
model.lasso.up <- train(
  hit_run ~., 
  data = train, 
  method = "glmnet",
  metric = "ROC", 
  family = "binomial",
  trControl = train.control,
  tuneGrid = data.frame(alpha = 1, lambda = lambda)
)

pred <- as.factor(predict(model.lasso.up, test))
confusionMatrix(pred, test$hit_run, positive="yes")
```

## ROC Curve

### Examine ROC curve

ROC curve for logistic regression with lasso:
```{r}
train$prob <- predict(model.lasso, train, type = "prob")[[2]]

library(plotROC)
ggplot(train, aes(d=hit_run, m=prob)) +
  geom_roc(labelround=2, n.cuts=15, labelsize=3) + 
  style_roc(major.breaks=seq(0, 1, .1),
            minor.breaks=seq(0, 1, .05),
            theme=theme_grey) +
  labs(title="ROC Plot")

```

ROC curve for extreme gradient boost:
```{r}
train$prob <- predict(model.gbm, train, type="prob")[[2]]

ggplot(train, aes(d=hit_run, m=prob)) +
  geom_roc(labelround=2, n.cuts=15, labelsize=3) + 
  style_roc(major.breaks=seq(0, 1, .1),
            minor.breaks=seq(0, 1, .05),
            theme=theme_grey) +
  labs(title="ROC Plot")

library(pROC)
auc(train$hit_run, train$prob)
```

## Adjust ROC cutoff
```{r}
test$prob <- predict(model.ann, test, type = "prob")[[2]]
test$pred.12 <- factor(test$prob > .73,
                       levels = c(FALSE, TRUE),
                       labels=c("no", "yes"))
confusionMatrix(test$pred.12, 
                test$hit_run, 
                positive="yes")

```


## Visualization

### Examine Gain and Lift Charts
```{r}
train$prob <- predict(model.xgb, train, type="prob")[[2]]

source("gain and lift charts.R")
lift(train$target, train$prob, positive="yes")
```

### XAI
```{r}

```

# Discussion

# References

